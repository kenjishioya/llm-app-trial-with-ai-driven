#!/usr/bin/env python3
"""
ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Task 3-3A-2: ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æŠ•å…¥

ä½¿ç”¨ä¾‹:
    python scripts/upload_test_documents.py
    python scripts/upload_test_documents.py --verify-only
    python scripts/upload_test_documents.py --category wikipedia
"""

import asyncio
import argparse
import sys
import os
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import time
from datetime import datetime
from tqdm import tqdm

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent / "backend"))

from services.document_pipeline import DocumentPipeline, DocumentPipelineError, ProcessingResult
from services.search_service import SearchService, SearchServiceError
from config import get_settings


class TestDocumentUploader:
    """ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå°‚ç”¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼"""

    def __init__(self, verbose: bool = False):
        """åˆæœŸåŒ–"""
        self.verbose = verbose
        self.settings = get_settings()
        self.pipeline = DocumentPipeline()
        self.search_service = SearchService()
        self.test_docs_dir = Path(__file__).parent.parent / "test_documents"
        self.manifest_file = self.test_docs_dir / "test_documents_manifest.json"
        self.results: List[Dict[str, Any]] = []

    async def load_manifest(self) -> Dict[str, Any]:
        """ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if not self.manifest_file.exists():
            raise FileNotFoundError(f"Manifest file not found: {self.manifest_file}")

        with open(self.manifest_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    async def upload_all_test_documents(self) -> Dict[str, Any]:
        """å…¨ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        print("ğŸš€ Starting test document upload process...")

        # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆèª­ã¿è¾¼ã¿
        manifest = await self.load_manifest()
        print(f"ğŸ“‹ Loaded manifest: {manifest['total_documents']} documents in {len(manifest['categories'])} categories")

        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        await self._health_check()

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        upload_summary = {
            "start_time": datetime.utcnow().isoformat(),
            "categories": {},
            "total_success": 0,
            "total_errors": 0,
            "total_chunks": 0
        }

        for category_name, category_info in manifest['categories'].items():
            print(f"\nğŸ“ Processing category: {category_name}")
            print(f"   Description: {category_info['description']}")
            print(f"   Files: {category_info['count']}")

            category_result = await self._upload_category(category_name, category_info)
            upload_summary["categories"][category_name] = category_result
            upload_summary["total_success"] += category_result["success_count"]
            upload_summary["total_errors"] += category_result["error_count"]
            upload_summary["total_chunks"] += category_result["total_chunks"]

        upload_summary["end_time"] = datetime.utcnow().isoformat()
        upload_summary["duration_seconds"] = (
            datetime.fromisoformat(upload_summary["end_time"]) -
            datetime.fromisoformat(upload_summary["start_time"])
        ).total_seconds()

        # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        self._print_upload_summary(upload_summary)

        return upload_summary

    async def upload_category(self, category_name: str) -> Dict[str, Any]:
        """ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        manifest = await self.load_manifest()

        if category_name not in manifest['categories']:
            raise ValueError(f"Category '{category_name}' not found in manifest")

        category_info = manifest['categories'][category_name]
        print(f"ğŸ“ Processing category: {category_name}")
        print(f"   Description: {category_info['description']}")

        await self._health_check()

        return await self._upload_category(category_name, category_info)

    async def _upload_category(self, category_name: str, category_info: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚«ãƒ†ã‚´ãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        category_dir = self.test_docs_dir / category_name
        files = category_info['files']

        success_count = 0
        error_count = 0
        total_chunks = 0
        results = []

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        with tqdm(files, desc=f"Uploading {category_name}", unit="file") as pbar:
            for filename in pbar:
                file_path = category_dir / filename
                pbar.set_postfix(file=filename[:20])

                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
                    if not file_path.exists():
                        raise FileNotFoundError(f"File not found: {file_path}")

                    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
                    if not self._is_supported_file(file_path):
                        if self.verbose:
                            print(f"â­ï¸  Skipping unsupported file: {filename}")
                        continue

                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
                    result = await self._upload_single_file(file_path, category_name)

                    if isinstance(result, ProcessingResult):
                        success_count += 1
                        total_chunks += result.chunks_count
                        results.append({
                            "file": filename,
                            "status": "success",
                            "document_id": result.document_id,
                            "chunks_count": result.chunks_count,
                            "processing_time": result.processing_time
                        })

                        if self.verbose:
                            print(f"âœ… {filename}: {result.chunks_count} chunks")

                except Exception as e:
                    error_count += 1
                    error_msg = str(e)
                    results.append({
                        "file": filename,
                        "status": "error",
                        "error": error_msg
                    })

                    if self.verbose:
                        print(f"âŒ {filename}: {error_msg}")

        return {
            "category": category_name,
            "success_count": success_count,
            "error_count": error_count,
            "total_chunks": total_chunks,
            "files_processed": len(files),
            "results": results
        }

    async def _upload_single_file(
        self,
        file_path: Path,
        category: str
    ) -> ProcessingResult:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        with open(file_path, 'rb') as f:
            file_content = f.read()

        # Content-Typeã®æ¨å®š
        content_type = self._detect_content_type(file_path)

        # ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = {
            "source": "test_documents",
            "category": category,
            "test_document": True,
            "file_size": len(file_content),
            "uploaded_via": "test_upload_script",
            "upload_timestamp": datetime.utcnow().isoformat()
        }

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†å®Ÿè¡Œ
        return await self.pipeline.process_document(
            file_content=file_content,
            filename=file_path.name,
            content_type=content_type,
            metadata=metadata
        )

    async def verify_upload(self) -> Dict[str, Any]:
        """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœã®æ¤œè¨¼"""
        print("ğŸ” Verifying uploaded test documents...")

        # æ¤œç´¢ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
        test_queries = [
            "Azure AI Search",
            "machine learning",
            "Python best practices",
            "cloud computing",
            "natural language processing"
        ]

        verification_results = {
            "timestamp": datetime.utcnow().isoformat(),
            "queries_tested": len(test_queries),
            "search_results": {}
        }

        for query in test_queries:
            try:
                print(f"ğŸ” Testing query: '{query}'")

                # æ¤œç´¢å®Ÿè¡Œ
                search_results = await self.search_service.search_documents(
                    query=query,
                    top_k=5
                )

                verification_results["search_results"][query] = {
                    "status": "success",
                    "results_count": len(search_results),
                    "top_score": search_results[0]["score"] if search_results else 0.0,
                    "has_test_documents": any(
                        result.get("metadata", {}).get("test_document", False)
                        for result in search_results
                    )
                }

                print(f"   Found {len(search_results)} results (top score: {search_results[0]['score']:.3f})" if search_results else "   No results found")

            except Exception as e:
                verification_results["search_results"][query] = {
                    "status": "error",
                    "error": str(e)
                }
                print(f"   âŒ Error: {e}")

        return verification_results

    async def _health_check(self) -> None:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        if self.verbose:
            print("ğŸ” Checking system health...")

        health = await self.pipeline.health_check()

        if health['status'] != 'healthy':
            print(f"âš ï¸  System health check failed: {health['status']}")
            for component, status in health.get('components', {}).items():
                if status['status'] != 'healthy':
                    print(f"   âŒ {component}: {status['status']}")
            raise RuntimeError("System is not healthy")

        if self.verbose:
            print("âœ… System health check passed")

    def _detect_content_type(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰Content-Typeã‚’æ¨å®š"""
        ext = file_path.suffix.lower()
        content_type_map = {
            '.pdf': 'application/pdf',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.txt': 'text/plain',
            '.md': 'text/markdown',
            '.markdown': 'text/markdown',
            '.json': 'application/json'
        }
        return content_type_map.get(ext, 'text/plain')

    def _is_supported_file(self, file_path: Path) -> bool:
        """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‹ãƒã‚§ãƒƒã‚¯"""
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        if file_path.suffix.lower() == '.json':
            return False

        content_type = self._detect_content_type(file_path)
        return self.pipeline.is_supported_file_type(content_type)

    def _print_upload_summary(self, summary: Dict[str, Any]) -> None:
        """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š UPLOAD SUMMARY")
        print("="*60)

        print(f"â±ï¸  Duration: {summary['duration_seconds']:.1f} seconds")
        print(f"âœ… Total Success: {summary['total_success']}")
        print(f"âŒ Total Errors: {summary['total_errors']}")
        print(f"ğŸ“„ Total Chunks Created: {summary['total_chunks']}")

        print("\nğŸ“ Category Breakdown:")
        for category, result in summary['categories'].items():
            success_rate = (result['success_count'] / result['files_processed'] * 100) if result['files_processed'] > 0 else 0
            print(f"   {category}: {result['success_count']}/{result['files_processed']} files ({success_rate:.1f}%) - {result['total_chunks']} chunks")

        if summary['total_errors'] > 0:
            print("\nâŒ Errors occurred. Use --verbose for details.")

        print("="*60)

    async def save_results(self, results: Dict[str, Any], output_file: Optional[Path] = None) -> None:
        """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = Path(f"test_upload_results_{timestamp}.json")

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ Results saved to: {output_file}")


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Upload test documents to Azure AI Search",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python scripts/upload_test_documents.py                    # Upload all test documents
  python scripts/upload_test_documents.py --category wikipedia  # Upload only wikipedia category
  python scripts/upload_test_documents.py --verify-only      # Only verify existing uploads
  python scripts/upload_test_documents.py --verbose          # Verbose output
        """
    )

    parser.add_argument(
        '--category',
        type=str,
        help='Upload only specific category (wikipedia, qa_datasets, technical_docs, sample_pdfs)'
    )
    parser.add_argument(
        '--verify-only',
        action='store_true',
        help='Only verify uploaded documents, do not upload'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Verbose output'
    )
    parser.add_argument(
        '--output',
        type=Path,
        help='Output file for results (JSON format)'
    )

    args = parser.parse_args()

    try:
        uploader = TestDocumentUploader(verbose=args.verbose)

        if args.verify_only:
            # æ¤œè¨¼ã®ã¿å®Ÿè¡Œ
            results = await uploader.verify_upload()
            print("\nâœ… Verification completed")
        elif args.category:
            # ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            results = await uploader.upload_category(args.category)
            print(f"\nâœ… Category '{args.category}' upload completed")
        else:
            # å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            results = await uploader.upload_all_test_documents()
            print("\nâœ… All test documents upload completed")

            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®æ¤œè¨¼
            print("\n" + "-"*40)
            verification_results = await uploader.verify_upload()
            results["verification"] = verification_results

        # çµæœä¿å­˜
        if args.output:
            await uploader.save_results(results, args.output)

    except KeyboardInterrupt:
        print("\nâš ï¸  Upload interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Upload failed: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
