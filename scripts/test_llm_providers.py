#!/usr/bin/env python3
"""
QRAI LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å‹•ä½œãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
=====================================

OpenRouterã€Google AI Studioã€Azure OpenAIï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã®
è©³ç´°ãªå‹•ä½œãƒ†ã‚¹ãƒˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/test_llm_providers.py
    python scripts/test_llm_providers.py --test chat
    python scripts/test_llm_providers.py --test streaming --provider openrouter
"""

import os
import sys
import time
import asyncio
import argparse
from typing import Dict, Any
from datetime import datetime

# ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
try:
    from openai import OpenAI
    import google.generativeai as genai
    from dotenv import load_dotenv
except ImportError as e:
    print(f"âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install openai google-generativeai python-dotenv")
    sys.exit(1)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()


class LLMPerformanceTester:
    """LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è©³ç´°ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.results = {}

    def log(self, message: str, level: str = "INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        if level == "ERROR":
            print(f"[{timestamp}] âŒ {message}")
        elif level == "SUCCESS":
            print(f"[{timestamp}] âœ… {message}")
        elif level == "WARNING":
            print(f"[{timestamp}] âš ï¸ {message}")
        elif self.verbose or level == "INFO":
            print(f"[{timestamp}] â„¹ï¸ {message}")

    def measure_time(self, start_time: float) -> float:
        """å®Ÿè¡Œæ™‚é–“æ¸¬å®š"""
        return round(time.time() - start_time, 2)

    async def test_chat_completion_openrouter(self) -> Dict[str, Any]:
        """OpenRouter ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ"""
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            return {"status": "skipped", "error": "API key not set"}

        try:
            client = OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

            # è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
            test_cases = [
                {
                    "name": "ç°¡å˜ãªè³ªå•",
                    "messages": [{"role": "user", "content": "Hello, how are you?"}],
                    "expected_tokens": 20,
                },
                {
                    "name": "æ—¥æœ¬èªå¯¾å¿œ",
                    "messages": [
                        {
                            "role": "user",
                            "content": "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚",
                        }
                    ],
                    "expected_tokens": 30,
                },
                {
                    "name": "ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è³ªå•",
                    "messages": [
                        {
                            "role": "user",
                            "content": "Write a simple Python function to calculate fibonacci numbers.",
                        }
                    ],
                    "expected_tokens": 100,
                },
                {
                    "name": "æ¨è«–ã‚¿ã‚¹ã‚¯",
                    "messages": [
                        {
                            "role": "user",
                            "content": "If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets?",
                        }
                    ],
                    "expected_tokens": 50,
                },
            ]

            results = []
            total_time = 0

            for test_case in test_cases:
                self.log(f"OpenRouter: {test_case['name']} ãƒ†ã‚¹ãƒˆä¸­...", "INFO")
                start_time = time.time()

                response = client.chat.completions.create(
                    model="deepseek/deepseek-r1:free",
                    messages=test_case["messages"],
                    max_tokens=test_case["expected_tokens"],
                    temperature=0.7,
                )

                elapsed_time = self.measure_time(start_time)
                total_time += elapsed_time

                if response.choices and response.choices[0].message.content:
                    content = response.choices[0].message.content.strip()
                    results.append(
                        {
                            "test": test_case["name"],
                            "success": True,
                            "response_length": len(content),
                            "elapsed_time": elapsed_time,
                            "usage": (
                                response.usage.model_dump() if response.usage else None
                            ),
                        }
                    )

                    if self.verbose:
                        self.log(
                            f"å¿œç­”: {content[:100]}{'...' if len(content) > 100 else ''}",
                            "INFO",
                        )
                else:
                    results.append(
                        {
                            "test": test_case["name"],
                            "success": False,
                            "error": "Empty response",
                        }
                    )

            success_rate = (
                sum(1 for r in results if r.get("success", False)) / len(results) * 100
            )
            avg_time = total_time / len(results)

            return {
                "status": "success",
                "provider": "openrouter",
                "model": "deepseek/deepseek-r1:free",
                "test_results": results,
                "summary": {
                    "success_rate": success_rate,
                    "total_time": total_time,
                    "average_time": avg_time,
                    "tests_count": len(results),
                },
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_streaming_openrouter(self) -> Dict[str, Any]:
        """OpenRouter ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            return {"status": "skipped", "error": "API key not set"}

        try:
            client = OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

            self.log("OpenRouter: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹...", "INFO")
            start_time = time.time()

            stream = client.chat.completions.create(
                model="deepseek/deepseek-r1:free",
                messages=[
                    {
                        "role": "user",
                        "content": "Write a short story about a robot learning to paint. Make it about 200 words.",
                    }
                ],
                max_tokens=300,
                temperature=0.7,
                stream=True,
            )

            chunks = []
            content_parts = []
            first_chunk_time = None

            for chunk in stream:
                if first_chunk_time is None:
                    first_chunk_time = self.measure_time(start_time)

                chunks.append(chunk)
                if chunk.choices and chunk.choices[0].delta.content:
                    content_parts.append(chunk.choices[0].delta.content)

            total_time = self.measure_time(start_time)
            full_content = "".join(content_parts)

            return {
                "status": "success",
                "provider": "openrouter",
                "streaming": True,
                "total_chunks": len(chunks),
                "content_length": len(full_content),
                "first_chunk_time": first_chunk_time,
                "total_time": total_time,
                "chunks_per_second": len(chunks) / total_time if total_time > 0 else 0,
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_chat_completion_google_ai(self) -> Dict[str, Any]:
        """Google AI ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ"""
        api_key = os.getenv("GOOGLE_AI_API_KEY")
        if not api_key:
            return {"status": "skipped", "error": "API key not set"}

        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemini-2.5-flash")

            # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
            test_cases = [
                {
                    "name": "ç°¡å˜ãªè³ªå•",
                    "prompt": "Hello, how are you today?",
                    "max_tokens": 50,
                },
                {
                    "name": "æ—¥æœ¬èªå¯¾å¿œ",
                    "prompt": "æ—¥æœ¬ã®æ–‡åŒ–ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
                    "max_tokens": 100,
                },
                {
                    "name": "å‰µä½œã‚¿ã‚¹ã‚¯",
                    "prompt": "Write a haiku about artificial intelligence.",
                    "max_tokens": 100,
                },
                {
                    "name": "åˆ†æã‚¿ã‚¹ã‚¯",
                    "prompt": "Analyze the pros and cons of renewable energy.",
                    "max_tokens": 200,
                },
            ]

            results = []
            total_time = 0

            for test_case in test_cases:
                self.log(f"Google AI: {test_case['name']} ãƒ†ã‚¹ãƒˆä¸­...", "INFO")
                start_time = time.time()

                response = model.generate_content(
                    test_case["prompt"],
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=test_case["max_tokens"], temperature=0.7
                    ),
                )

                elapsed_time = self.measure_time(start_time)
                total_time += elapsed_time

                if response.text:
                    content = response.text.strip()
                    results.append(
                        {
                            "test": test_case["name"],
                            "success": True,
                            "response_length": len(content),
                            "elapsed_time": elapsed_time,
                        }
                    )

                    if self.verbose:
                        self.log(
                            f"å¿œç­”: {content[:100]}{'...' if len(content) > 100 else ''}",
                            "INFO",
                        )
                else:
                    results.append(
                        {
                            "test": test_case["name"],
                            "success": False,
                            "error": "Empty response",
                        }
                    )

            success_rate = (
                sum(1 for r in results if r.get("success", False)) / len(results) * 100
            )
            avg_time = total_time / len(results)

            return {
                "status": "success",
                "provider": "google_ai",
                "model": "gemini-2.5-flash",
                "test_results": results,
                "summary": {
                    "success_rate": success_rate,
                    "total_time": total_time,
                    "average_time": avg_time,
                    "tests_count": len(results),
                },
            }

        except Exception as e:
            return {"status": "failed", "error": str(e)}

    async def test_embedding_comparison(self) -> Dict[str, Any]:
        """åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
        results = {}

        # OpenRouteråŸ‹ã‚è¾¼ã¿ãƒ†ã‚¹ãƒˆ
        openrouter_key = os.getenv("OPENROUTER_API_KEY")
        if openrouter_key:
            try:
                client = OpenAI(
                    api_key=openrouter_key, base_url="https://openrouter.ai/api/v1"
                )

                test_text = "This is a sample text for embedding generation."
                start_time = time.time()

                response = client.embeddings.create(
                    model="text-embedding-ada-002", input=test_text
                )

                elapsed_time = self.measure_time(start_time)

                if response.data and len(response.data) > 0:
                    embedding = response.data[0].embedding
                    results["openrouter"] = {
                        "status": "success",
                        "dimensions": len(embedding),
                        "elapsed_time": elapsed_time,
                        "model": "text-embedding-ada-002",
                    }
                else:
                    results["openrouter"] = {
                        "status": "failed",
                        "error": "No embedding data",
                    }

            except Exception as e:
                results["openrouter"] = {"status": "failed", "error": str(e)}

        # Google AIåŸ‹ã‚è¾¼ã¿ãƒ†ã‚¹ãƒˆï¼ˆText Embedding APIãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        google_key = os.getenv("GOOGLE_AI_API_KEY")
        if google_key:
            try:
                genai.configure(api_key=google_key)

                test_text = "This is a sample text for embedding generation."
                start_time = time.time()

                # Google AI ã®embedding APIã‚’ä½¿ç”¨
                response = genai.embed_content(
                    model="models/text-embedding-004", content=test_text
                )

                elapsed_time = self.measure_time(start_time)

                if response and "embedding" in response:
                    embedding = response["embedding"]
                    results["google_ai"] = {
                        "status": "success",
                        "dimensions": len(embedding),
                        "elapsed_time": elapsed_time,
                        "model": "text-embedding-004",
                    }
                else:
                    results["google_ai"] = {
                        "status": "failed",
                        "error": "No embedding data",
                    }

            except Exception as e:
                results["google_ai"] = {"status": "failed", "error": str(e)}

        return results

    async def run_performance_tests(
        self, test_type: str = "all", provider_filter: str = None
    ) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.log("ğŸ”§ QRAI LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è©³ç´°ãƒ†ã‚¹ãƒˆé–‹å§‹", "INFO")
        self.log("=" * 60, "INFO")

        all_results = {}

        # ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ
        if test_type in ["all", "chat"]:
            self.log("\nğŸ“ ãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ", "INFO")
            self.log("-" * 30, "INFO")

            if not provider_filter or provider_filter == "openrouter":
                self.log("OpenRouter ãƒ†ã‚¹ãƒˆä¸­...", "INFO")
                result = await self.test_chat_completion_openrouter()
                all_results["openrouter_chat"] = result

                if result["status"] == "success":
                    summary = result["summary"]
                    self.log(
                        f"âœ… OpenRouter: æˆåŠŸç‡ {summary['success_rate']:.1f}%, å¹³å‡å¿œç­”æ™‚é–“ {summary['average_time']:.2f}ç§’",
                        "SUCCESS",
                    )
                else:
                    self.log(
                        f"âŒ OpenRouter: {result.get('error', 'Unknown error')}",
                        "ERROR",
                    )

            if not provider_filter or provider_filter == "google_ai":
                self.log("Google AI ãƒ†ã‚¹ãƒˆä¸­...", "INFO")
                result = await self.test_chat_completion_google_ai()
                all_results["google_ai_chat"] = result

                if result["status"] == "success":
                    summary = result["summary"]
                    self.log(
                        f"âœ… Google AI: æˆåŠŸç‡ {summary['success_rate']:.1f}%, å¹³å‡å¿œç­”æ™‚é–“ {summary['average_time']:.2f}ç§’",
                        "SUCCESS",
                    )
                else:
                    self.log(
                        f"âŒ Google AI: {result.get('error', 'Unknown error')}", "ERROR"
                    )

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        if test_type in ["all", "streaming"]:
            self.log("\nğŸŒŠ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ†ã‚¹ãƒˆ", "INFO")
            self.log("-" * 30, "INFO")

            if not provider_filter or provider_filter == "openrouter":
                result = await self.test_streaming_openrouter()
                all_results["openrouter_streaming"] = result

                if result["status"] == "success":
                    self.log(
                        f"âœ… OpenRouter ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {result['total_chunks']} chunks, åˆå›å¿œç­” {result['first_chunk_time']}ç§’",
                        "SUCCESS",
                    )
                else:
                    self.log(
                        f"âŒ OpenRouter ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {result.get('error', 'Unknown error')}",
                        "ERROR",
                    )

        # åŸ‹ã‚è¾¼ã¿ãƒ†ã‚¹ãƒˆ
        if test_type in ["all", "embedding"]:
            self.log("\nğŸ§® åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ãƒ†ã‚¹ãƒˆ", "INFO")
            self.log("-" * 30, "INFO")

            embedding_results = await self.test_embedding_comparison()
            all_results["embedding"] = embedding_results

            for provider, result in embedding_results.items():
                if result["status"] == "success":
                    self.log(
                        f"âœ… {provider}: {result['dimensions']} æ¬¡å…ƒ, {result['elapsed_time']}ç§’",
                        "SUCCESS",
                    )
                else:
                    self.log(
                        f"âŒ {provider}: {result.get('error', 'Unknown error')}",
                        "ERROR",
                    )

        # çµæœã‚µãƒãƒªãƒ¼
        self.log("\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼", "INFO")
        self.log("=" * 60, "INFO")

        successful_tests = 0
        total_tests = 0

        for test_name, result in all_results.items():
            total_tests += 1
            if isinstance(result, dict) and result.get("status") == "success":
                successful_tests += 1
                self.log(f"âœ… {test_name}: æˆåŠŸ", "SUCCESS")
            elif isinstance(result, dict):
                # åŸ‹ã‚è¾¼ã¿ãƒ†ã‚¹ãƒˆã¯è¤‡æ•°ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®çµæœ
                if test_name == "embedding":
                    for provider, prov_result in result.items():
                        total_tests += 1
                        if prov_result.get("status") == "success":
                            successful_tests += 1
                            self.log(f"âœ… {test_name}_{provider}: æˆåŠŸ", "SUCCESS")
                        else:
                            self.log(f"âŒ {test_name}_{provider}: å¤±æ•—", "ERROR")
                else:
                    self.log(f"âŒ {test_name}: å¤±æ•—", "ERROR")

        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        self.log(
            f"\nğŸ¯ ç·åˆæˆåŠŸç‡: {success_rate:.1f}% ({successful_tests}/{total_tests})",
            "SUCCESS",
        )

        return {
            "summary": {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "success_rate": success_rate,
            },
            "detailed_results": all_results,
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="QRAI LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è©³ç´°ãƒ†ã‚¹ãƒˆ")
    parser.add_argument(
        "--test",
        choices=["all", "chat", "streaming", "embedding"],
        default="all",
        help="å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆã‚¿ã‚¤ãƒ—",
    )
    parser.add_argument(
        "--provider",
        choices=["openrouter", "google_ai", "azure_openai"],
        help="ç‰¹å®šã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã¿ãƒ†ã‚¹ãƒˆ",
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°å‡ºåŠ›")

    args = parser.parse_args()

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester = LLMPerformanceTester(verbose=args.verbose)

    try:
        result = asyncio.run(tester.run_performance_tests(args.test, args.provider))

        # çµ‚äº†ã‚³ãƒ¼ãƒ‰æ±ºå®š
        summary = result.get("summary", {})
        if summary.get("successful_tests", 0) == 0:
            sys.exit(1)  # å…¨ãƒ†ã‚¹ãƒˆå¤±æ•—

        sys.exit(0)  # æ­£å¸¸çµ‚äº†

    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
