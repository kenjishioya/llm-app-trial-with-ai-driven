#!/usr/bin/env python3
"""
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CLIã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Task 3-2B-1: CLIã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨ä¾‹:
    python scripts/upload_document.py file.pdf
    python scripts/upload_document.py --batch documents/
    python scripts/upload_document.py --help
"""

import asyncio
import argparse
import sys
import os
from pathlib import Path
from typing import List, Dict, Any, Optional
import json
import time
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent / "backend"))

from services.document_pipeline import DocumentPipeline, DocumentPipelineError, ProcessingResult
from services.blob_storage_service import BlobStorageService, BlobStorageError
from services.document_parser import DocumentParser, DocumentParserError
from services.search_service import SearchService, SearchServiceError
from config import get_settings


class DocumentUploader:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, verbose: bool = False):
        """åˆæœŸåŒ–"""
        self.verbose = verbose
        self.settings = get_settings()
        self.pipeline = DocumentPipeline()
        self.results: List[Dict[str, Any]] = []

    async def upload_single_file(
        self,
        file_path: Path,
        metadata: Optional[Dict[str, Any]] = None
    ) -> ProcessingResult:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")

        if not file_path.is_file():
            raise ValueError(f"Path is not a file: {file_path}")

        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        try:
            with open(file_path, 'rb') as f:
                file_content = f.read()
        except Exception as e:
            raise DocumentPipelineError(f"Failed to read file {file_path}: {e}")

        # Content-Typeã®æ¨å®š
        content_type = self._detect_content_type(file_path)

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        file_metadata = {
            "source_path": str(file_path.absolute()),
            "file_size": len(file_content),
            "uploaded_via": "cli_script",
            "upload_timestamp": datetime.utcnow().isoformat(),
            **(metadata or {})
        }

        if self.verbose:
            print(f"ğŸ“„ Processing: {file_path.name}")
            print(f"   Size: {len(file_content):,} bytes")
            print(f"   Type: {content_type}")

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†å®Ÿè¡Œ
        start_time = time.time()
        try:
            result = await self.pipeline.process_document(
                file_content=file_content,
                filename=file_path.name,
                content_type=content_type,
                metadata=file_metadata
            )

            processing_time = time.time() - start_time

            if self.verbose:
                print(f"âœ… Success: {result.chunks_count} chunks indexed in {processing_time:.2f}s")
                print(f"   Document ID: {result.document_id}")
                print(f"   Blob URL: {result.blob_url}")

            return result

        except Exception as e:
            processing_time = time.time() - start_time
            if self.verbose:
                print(f"âŒ Failed: {str(e)} (after {processing_time:.2f}s)")
            raise

    async def upload_batch(
        self,
        directory: Path,
        pattern: str = "*",
        recursive: bool = False
    ) -> List[ProcessingResult]:
        """ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        if not directory.exists():
            raise FileNotFoundError(f"Directory not found: {directory}")

        if not directory.is_dir():
            raise ValueError(f"Path is not a directory: {directory}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
        if recursive:
            files = list(directory.rglob(pattern))
        else:
            files = list(directory.glob(pattern))

        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
        files = [f for f in files if f.is_file() and self._is_supported_file(f)]

        if not files:
            print(f"âš ï¸  No supported files found in {directory}")
            return []

        print(f"ğŸ“ Found {len(files)} files to process")

        results = []
        success_count = 0
        error_count = 0

        for i, file_path in enumerate(files, 1):
            try:
                if self.verbose:
                    print(f"\n[{i}/{len(files)}] ", end="")
                else:
                    print(f"Processing {file_path.name}... ", end="", flush=True)

                result = await self.upload_single_file(file_path)
                results.append(result)
                success_count += 1

                if not self.verbose:
                    print("âœ…")

            except Exception as e:
                error_count += 1
                error_info = {
                    "file_path": str(file_path),
                    "error": str(e),
                    "timestamp": datetime.utcnow().isoformat()
                }
                results.append(error_info)

                if self.verbose:
                    print(f"âŒ Error: {e}")
                else:
                    print(f"âŒ {e}")

        print(f"\nğŸ“Š Batch upload completed:")
        print(f"   âœ… Success: {success_count}")
        print(f"   âŒ Errors: {error_count}")
        print(f"   ğŸ“„ Total: {len(files)}")

        return results

    def _detect_content_type(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰Content-Typeã‚’æ¨å®š"""
        ext = file_path.suffix.lower()
        content_type_map = {
            '.pdf': 'application/pdf',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.txt': 'text/plain',
            '.md': 'text/markdown',
            '.markdown': 'text/markdown'
        }
        return content_type_map.get(ext, 'application/octet-stream')

    def _is_supported_file(self, file_path: Path) -> bool:
        """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‹ãƒã‚§ãƒƒã‚¯"""
        content_type = self._detect_content_type(file_path)
        return self.pipeline.is_supported_file_type(content_type)

    async def health_check(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ” Checking system health...")

        health = await self.pipeline.health_check()

        print(f"Overall Status: {health['status'].upper()}")
        print("\nComponents:")

        for component, status in health.get('components', {}).items():
            status_icon = "âœ…" if status['status'] == 'healthy' else "âŒ"
            print(f"  {status_icon} {component}: {status['status']}")

        if health['status'] != 'healthy':
            print("\nâš ï¸  Some components are not healthy. Upload may fail.")
            return health

        print("\nâœ… All systems ready for upload!")
        return health

    def save_results(self, results: List[Any], output_file: Path) -> None:
        """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # ProcessingResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
            serializable_results = []
            for result in results:
                if hasattr(result, '__dict__'):
                    # dataclassã®å ´åˆ
                    result_dict = {
                        k: v for k, v in result.__dict__.items()
                        if not k.startswith('_')
                    }
                    serializable_results.append(result_dict)
                else:
                    # æ—¢ã«è¾æ›¸ã®å ´åˆï¼ˆã‚¨ãƒ©ãƒ¼æƒ…å ±ãªã©ï¼‰
                    serializable_results.append(result)

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, indent=2, ensure_ascii=False, default=str)

            print(f"ğŸ“„ Results saved to: {output_file}")

        except Exception as e:
            print(f"âš ï¸  Failed to save results: {e}")


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CLIãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  python scripts/upload_document.py document.pdf

  # ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  python scripts/upload_document.py --batch documents/

  # å†å¸°çš„ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  python scripts/upload_document.py --batch documents/ --recursive

  # è©³ç´°ãƒ­ã‚°ä»˜ãã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  python scripts/upload_document.py document.pdf --verbose

  # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®ã¿
  python scripts/upload_document.py --health-check

  # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
  python scripts/upload_document.py --batch documents/ --output results.json
        """
    )

    # å¼•æ•°å®šç¾©
    parser.add_argument(
        'path',
        nargs='?',
        type=Path,
        help='ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹'
    )

    parser.add_argument(
        '--batch',
        action='store_true',
        help='ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰'
    )

    parser.add_argument(
        '--recursive',
        action='store_true',
        help='å†å¸°çš„ã«ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚å‡¦ç†'
    )

    parser.add_argument(
        '--pattern',
        default='*',
        help='ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: *ï¼‰'
    )

    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º'
    )

    parser.add_argument(
        '--output', '-o',
        type=Path,
        help='çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜'
    )

    parser.add_argument(
        '--health-check',
        action='store_true',
        help='ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿè¡Œ'
    )

    args = parser.parse_args()

    # å¼•æ•°æ¤œè¨¼
    if not args.health_check and not args.path:
        parser.error("ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ --health-check ãŒå¿…è¦ã§ã™")

    try:
        uploader = DocumentUploader(verbose=args.verbose)

        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        if args.health_check:
            await uploader.health_check()
            return

        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ï¼‰
        health = await uploader.health_check()
        if health['status'] != 'healthy':
            print("\nâš ï¸  System is not healthy. Continue anyway? (y/N): ", end="")
            if input().lower() != 'y':
                print("Upload cancelled.")
                sys.exit(1)

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
        results = []
        start_time = time.time()

        if args.batch:
            results = await uploader.upload_batch(
                directory=args.path,
                pattern=args.pattern,
                recursive=args.recursive
            )
        else:
            result = await uploader.upload_single_file(args.path)
            results = [result]

        total_time = time.time() - start_time

        # çµæœã‚µãƒãƒªãƒ¼
        print(f"\nğŸ‰ Upload completed in {total_time:.2f}s")

        if args.output:
            uploader.save_results(results, args.output)

    except KeyboardInterrupt:
        print("\n\nâš ï¸  Upload cancelled by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Upload failed: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
