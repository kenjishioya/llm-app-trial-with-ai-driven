#!/usr/bin/env python3
"""
QRAI LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
=========================================

OpenRouterã€Google AI Studioã€Azure OpenAIï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã®æ¥ç¶šç¢ºèªã¨
åŸºæœ¬çš„ãªå‹•ä½œãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/check_llm_config.py
    python scripts/check_llm_config.py --provider openrouter
    python scripts/check_llm_config.py --verbose
"""

import os
import sys
import asyncio
import argparse
from typing import Dict, Any, Optional
from datetime import datetime

# ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
try:
    from openai import OpenAI
    import google.generativeai as genai
    from dotenv import load_dotenv
except ImportError as e:
    print(f"âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install openai google-generativeai python-dotenv")
    sys.exit(1)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()


class LLMProviderTester:
    """LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.results = {}

    def log(self, message: str, level: str = "INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        if level == "ERROR":
            print(f"[{timestamp}] âŒ {message}")
        elif level == "SUCCESS":
            print(f"[{timestamp}] âœ… {message}")
        elif level == "WARNING":
            print(f"[{timestamp}] âš ï¸ {message}")
        elif self.verbose or level == "INFO":
            print(f"[{timestamp}] â„¹ï¸ {message}")

    async def check_openrouter(self) -> Dict[str, Any]:
        """OpenRouteræ¥ç¶šç¢ºèª"""
        provider_name = "OpenRouter"
        api_key = os.getenv("OPENROUTER_API_KEY")

        if not api_key:
            self.log(
                f"{provider_name}: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (OPENROUTER_API_KEY)",
                "ERROR",
            )
            return {"status": "failed", "error": "API key not set"}

        self.log(f"{provider_name}: æ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹...", "INFO")

        try:
            client = OpenAI(api_key=api_key, base_url="https://openrouter.ai/api/v1")

            # åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ
            response = client.chat.completions.create(
                model="deepseek/deepseek-r1:free",
                messages=[
                    {
                        "role": "user",
                        "content": "Hello! Please respond with 'OpenRouter is working!'",
                    }
                ],
                max_tokens=50,
                temperature=0.7,
            )

            if response.choices and response.choices[0].message.content:
                content = response.choices[0].message.content.strip()
                self.log(f"{provider_name}: æ¥ç¶šæˆåŠŸ", "SUCCESS")
                self.log(f"{provider_name}: ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}", "INFO")

                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ãƒ†ã‚¹ãƒˆ
                try:
                    models_response = client.models.list()
                    available_models = (
                        len(models_response.data)
                        if hasattr(models_response, "data")
                        else 0
                    )
                    self.log(
                        f"{provider_name}: åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°: {available_models}", "INFO"
                    )
                except Exception as e:
                    self.log(f"{provider_name}: ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—å¤±æ•—: {e}", "WARNING")

                return {
                    "status": "success",
                    "response": content,
                    "model": "deepseek/deepseek-r1:free",
                    "usage": response.usage.model_dump() if response.usage else None,
                }
            else:
                self.log(f"{provider_name}: ç©ºã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹", "ERROR")
                return {"status": "failed", "error": "Empty response"}

        except Exception as e:
            self.log(f"{provider_name}: æ¥ç¶šå¤±æ•— - {str(e)}", "ERROR")
            return {"status": "failed", "error": str(e)}

    async def check_google_ai(self) -> Dict[str, Any]:
        """Google AI Studioæ¥ç¶šç¢ºèª"""
        provider_name = "Google AI"
        api_key = os.getenv("GOOGLE_AI_API_KEY")

        if not api_key:
            self.log(
                f"{provider_name}: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (GOOGLE_AI_API_KEY)",
                "ERROR",
            )
            return {"status": "failed", "error": "API key not set"}

        self.log(f"{provider_name}: æ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹...", "INFO")

        try:
            genai.configure(api_key=api_key)

            # åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ç¢ºèª
            try:
                models = list(genai.list_models())
                available_models = [
                    m.name
                    for m in models
                    if "generateContent" in m.supported_generation_methods
                ]
                self.log(
                    f"{provider_name}: åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«æ•°: {len(available_models)}",
                    "INFO",
                )
            except Exception as e:
                self.log(f"{provider_name}: ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—å¤±æ•—: {e}", "WARNING")
                available_models = []

            # åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ
            model = genai.GenerativeModel("gemini-2.5-flash")
            response = model.generate_content(
                "Hello! Please respond with 'Google AI is working!'",
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=50, temperature=0.7
                ),
            )

            if response.text:
                content = response.text.strip()
                self.log(f"{provider_name}: æ¥ç¶šæˆåŠŸ", "SUCCESS")
                self.log(f"{provider_name}: ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}", "INFO")

                return {
                    "status": "success",
                    "response": content,
                    "model": "gemini-2.5-flash",
                    "available_models": len(available_models),
                }
            else:
                self.log(f"{provider_name}: ç©ºã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹", "ERROR")
                return {"status": "failed", "error": "Empty response"}

        except Exception as e:
            self.log(f"{provider_name}: æ¥ç¶šå¤±æ•— - {str(e)}", "ERROR")
            return {"status": "failed", "error": str(e)}

    async def check_azure_openai(self) -> Dict[str, Any]:
        """Azure OpenAIæ¥ç¶šç¢ºèª"""
        provider_name = "Azure OpenAI"
        api_key = os.getenv("AZURE_OPENAI_API_KEY")
        endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")

        if not api_key or not endpoint:
            self.log(
                f"{provider_name}: APIã‚­ãƒ¼ã¾ãŸã¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                "WARNING",
            )
            return {"status": "skipped", "error": "API key or endpoint not set"}

        self.log(f"{provider_name}: æ¥ç¶šãƒ†ã‚¹ãƒˆé–‹å§‹...", "INFO")

        try:
            from openai import AzureOpenAI

            client = AzureOpenAI(
                api_key=api_key,
                azure_endpoint=endpoint,
                api_version="2024-02-15-preview",
            )

            # åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆå®Œäº†ãƒ†ã‚¹ãƒˆ
            response = client.chat.completions.create(
                model="gpt-4o-mini",  # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
                messages=[
                    {
                        "role": "user",
                        "content": "Hello! Please respond with 'Azure OpenAI is working!'",
                    }
                ],
                max_tokens=50,
                temperature=0.7,
            )

            if response.choices and response.choices[0].message.content:
                content = response.choices[0].message.content.strip()
                self.log(f"{provider_name}: æ¥ç¶šæˆåŠŸ", "SUCCESS")
                self.log(f"{provider_name}: ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}", "INFO")

                return {
                    "status": "success",
                    "response": content,
                    "model": "gpt-4o-mini",
                    "endpoint": endpoint,
                    "usage": response.usage.model_dump() if response.usage else None,
                }
            else:
                self.log(f"{provider_name}: ç©ºã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹", "ERROR")
                return {"status": "failed", "error": "Empty response"}

        except Exception as e:
            self.log(f"{provider_name}: æ¥ç¶šå¤±æ•— - {str(e)}", "ERROR")
            return {"status": "failed", "error": str(e)}

    async def run_all_tests(
        self, provider_filter: Optional[str] = None
    ) -> Dict[str, Any]:
        """å…¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.log("ğŸ” QRAI LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šç¢ºèªé–‹å§‹", "INFO")
        self.log("=" * 50, "INFO")

        # ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
        tests = {
            "openrouter": self.check_openrouter,
            "google_ai": self.check_google_ai,
            "azure_openai": self.check_azure_openai,
        }

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if provider_filter:
            if provider_filter in tests:
                tests = {provider_filter: tests[provider_filter]}
            else:
                self.log(f"ä¸æ˜ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider_filter}", "ERROR")
                return {"error": f"Unknown provider: {provider_filter}"}

        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        for provider_name, test_func in tests.items():
            self.log(f"\n--- {provider_name.upper()} ãƒ†ã‚¹ãƒˆ ---", "INFO")
            result = await test_func()
            self.results[provider_name] = result

        # çµæœã‚µãƒãƒªãƒ¼
        self.log("\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼", "INFO")
        self.log("=" * 50, "INFO")

        success_count = 0
        total_count = 0

        for provider_name, result in self.results.items():
            total_count += 1
            status = result.get("status", "unknown")

            if status == "success":
                success_count += 1
                self.log(f"âœ… {provider_name}: æ­£å¸¸", "SUCCESS")
            elif status == "skipped":
                self.log(f"â­ï¸ {provider_name}: ã‚¹ã‚­ãƒƒãƒ— (è¨­å®šãªã—)", "WARNING")
            else:
                error = result.get("error", "Unknown error")
                self.log(f"âŒ {provider_name}: å¤±æ•— ({error})", "ERROR")

        # æ¨å¥¨è¨­å®š
        if success_count > 0:
            self.log(
                f"\nğŸ‰ {success_count}/{total_count} ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™",
                "SUCCESS",
            )

            # æ¨å¥¨è¨­å®šææ¡ˆ
            if (
                "openrouter" in self.results
                and self.results["openrouter"]["status"] == "success"
            ):
                self.log("ğŸ’¡ æ¨å¥¨: OpenRouterã‚’ãƒ—ãƒ©ã‚¤ãƒãƒªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«è¨­å®š", "INFO")
            elif (
                "google_ai" in self.results
                and self.results["google_ai"]["status"] == "success"
            ):
                self.log("ğŸ’¡ æ¨å¥¨: Google AIã‚’ãƒ—ãƒ©ã‚¤ãƒãƒªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«è¨­å®š", "INFO")
        else:
            self.log("âš ï¸ åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“", "WARNING")
            self.log(
                "ğŸ“– è¨­å®šã‚¬ã‚¤ãƒ‰: docs/environment_setup.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„", "INFO"
            )

        return {
            "summary": {
                "total": total_count,
                "success": success_count,
                "failed": total_count - success_count,
            },
            "results": self.results,
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="QRAI LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®šç¢ºèª")
    parser.add_argument(
        "--provider",
        choices=["openrouter", "google_ai", "azure_openai"],
        help="ç‰¹å®šã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ã¿ãƒ†ã‚¹ãƒˆ",
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°å‡ºåŠ›")

    args = parser.parse_args()

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester = LLMProviderTester(verbose=args.verbose)

    try:
        result = asyncio.run(tester.run_all_tests(args.provider))

        # çµ‚äº†ã‚³ãƒ¼ãƒ‰æ±ºå®š
        if "error" in result:
            sys.exit(1)

        summary = result.get("summary", {})
        if summary.get("success", 0) == 0:
            sys.exit(1)  # å…¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å¤±æ•—

        sys.exit(0)  # æ­£å¸¸çµ‚äº†

    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
